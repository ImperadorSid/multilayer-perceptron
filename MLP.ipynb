{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import load_file as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     2,
     22
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Função update - alterar o valor dos x e passar adiante (u e g)\n",
    "class Neuron:\n",
    "  def __init__(self, x=None, w=None, function=sigmoid):\n",
    "    self.x = x\n",
    "    self.u = None\n",
    "    self.pd = None\n",
    "    self.function = function\n",
    "    \n",
    "    if type(self.x) is float or type(self.x) is int:\n",
    "      # Bias ou entrada\n",
    "      self.w = None\n",
    "      self.g = self.x\n",
    "    elif type(self.x) is list:\n",
    "      # Normal\n",
    "      self.w = w if type(w) is np.ndarray else np.random.random(len(self.x))\n",
    "      self.u = self.x @ self.w\n",
    "      self.g = self.function(self.u)\n",
    "    else:\n",
    "      # Não-inicializado\n",
    "      self.w = w if w is None or type(w) is np.ndarray else np.random.random(w)\n",
    "      self.g = None\n",
    "      \n",
    "  def update(self, new_x):\n",
    "      self.x = new_x\n",
    "      if not self.is_bias():\n",
    "        self.u = self.x @ self.w\n",
    "        self.g = self.function(self.u)\n",
    "      else:\n",
    "        self.g = self.x\n",
    "  \n",
    "  is_bias = lambda self: True if self.w is None else False\n",
    "  __repr__ = lambda self: '{} @ {} -> {}'.format(self.x, self.w, self.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     16,
     38,
     59,
     73
    ]
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "  def __init__(self, topology):\n",
    "    self.topology = topology\n",
    "    \n",
    "    self.init_neurons()\n",
    "#     self.inputs = [.05, .1]\n",
    "#     self.desired = [.01, .99]\n",
    "#     self.learning_rate = 0.5\n",
    "#     self.layers = [[Neuron(.05), Neuron(.1), Neuron(1)]]\n",
    "#     self.layers += [[Neuron([e.g for e in self.layers[0]], np.array([.15, .2, .35])), \n",
    "#                      Neuron([e.g for e in self.layers[0]], np.array([.25, .3, .35])), \n",
    "#                      Neuron(1)]]\n",
    "#     self.layers += [[Neuron([e.g for e in self.layers[1]], np.array([.4, .45, .6])), \n",
    "#                      Neuron([e.g for e in self.layers[1]], np.array([.5, .55, .6]))]]\n",
    "    \n",
    "    \n",
    "  def init_neurons(self):\n",
    "    # Camada de entrada\n",
    "    self.layers = [[Neuron() for i in range(self.topology[0])]]\n",
    "    self.layers[0] += [Neuron(1)] # Bias \n",
    "    \n",
    "    # Camadas ocultas e de saída\n",
    "    for i in range(1, len(self.topology)):\n",
    "      self.layers += [[Neuron(w=len(self.layers[i - 1])) for j in range(self.topology[i])]]\n",
    "      if i != len(self.topology) - 1: self.layers[i] += [Neuron(1)] # Bias\n",
    "\n",
    "  def update_neurons(self):\n",
    "    \n",
    "    # Camada de entrada\n",
    "    [self.layers[0][i].update(self.inputs[i]) for i in range(len(self.inputs))]\n",
    "    \n",
    "    # Camadas ocultas e de saída\n",
    "    for i in range(1, len(self.layers)):\n",
    "      [n.update([e.g for e in self.layers[i - 1]]) for n in self.layers[i] if not n.is_bias()]\n",
    "      \n",
    "    print(self.layers, '\\n')\n",
    "#       print('Camada', i, '\\n', self.layers[i])\n",
    "        \n",
    "  def update_weights(self):\n",
    "    # Camada de saída\n",
    "    for i in range(len(self.layers[-1])):\n",
    "      # Derivada parcial\n",
    "      neuron = self.layers[-1][i]\n",
    "      neuron.pd = - (self.desired[i] - neuron.g) * neuron.g * (1 - neuron.g)\n",
    "      # Pesos\n",
    "      for j in range(len(neuron.w)):\n",
    "        neuron.w[j] -= self.learning_rate * neuron.pd * self.layers[-2][j].g\n",
    "          \n",
    "    # Camadas ocultas\n",
    "    for i in range(len(self.layers) - 2, 0, -1):\n",
    "      for j in range(len(self.layers[i])):\n",
    "        # Derivada parcial\n",
    "        neuron = self.layers[i][j]\n",
    "        descendents = sum([n.pd * n.w[j] for n in self.layers[i + 1] if not n.is_bias()])\n",
    "        neuron.pd = descendents * neuron.g * (1 - neuron.g)\n",
    "        # Pesos\n",
    "        for k in range(len(neuron.w)):\n",
    "          neuron.w[k] -= self.learning_rate * neuron.pd * neuron.x[k]\n",
    "  \n",
    "  def update_errors(self):\n",
    "    out_layer = self.layers[-1]\n",
    "    out_length = len(out_layer)\n",
    "    \n",
    "    self.errors = [(out_layer[i].g - self.desired[i]) ** 2 for i in range(out_length)]\n",
    "    self.total_error = sum(self.errors) / 2\n",
    "    \n",
    "  def train(self, test_data, learning_rate=.1, precision=10**-6):\n",
    "    for index, sample in test_data.iterrows():\n",
    "      self.inputs = sample[:self.topology[0]].tolist()\n",
    "      self.desired = sample[self.topology[0]:].tolist()\n",
    "      \n",
    "      self.update_neurons()\n",
    "  \n",
    "  def __repr__(self):\n",
    "    result = 'Camada 0 - Entrada\\n{}\\n\\n'.format(self.layers[0])\n",
    "    for i in range(1, len(self.layers) - 1): result += 'Camada {} - Escondida \\n{}\\n\\n'.format(i, self.layers[i])\n",
    "    result += 'Camada {} - Saída\\n{}\\n\\n'.format(len(self.layers) - 1, self.layers[-1])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/xor.csv')\n",
    "df = df.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 @ None -> 0, 0 @ None -> 0, 1 @ None -> 1], [[0, 0, 1] @ [0.20363798 0.87531077 0.48961717] -> 0.6200162433481852, [0, 0, 1] @ [0.67462569 0.72748948 0.70954966] -> 0.6703016426004095, [0, 0, 1] @ [0.08450711 0.39602625 0.76317477] -> 0.6820426138210194, 1 @ None -> 1], [[0.6200162433481852, 0.6703016426004095, 0.6820426138210194, 1] @ [0.941715   0.17400685 0.11072998 0.12342108] -> 0.7108383793569891, [0.6200162433481852, 0.6703016426004095, 0.6820426138210194, 1] @ [0.91412153 0.12339591 0.34822553 0.65384699] -> 0.8235859794832703, 1 @ None -> 1], [[0.7108383793569891, 0.8235859794832703, 1] @ [0.10919312 0.55298947 0.62048998] -> 0.76015746824144, [0.7108383793569891, 0.8235859794832703, 1] @ [0.33673835 0.13619378 0.45871741] -> 0.6921630400959163]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = MLP([2, 3, 2, 2])\n",
    "a.train(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
