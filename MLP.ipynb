{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     1,
     21
    ]
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "  def __init__(self, x=None, w=None, function=sigmoid):\n",
    "    self.x = x\n",
    "    self.u = None\n",
    "    self.pd = None\n",
    "    self.function = function\n",
    "    \n",
    "    if type(self.x) is float or type(self.x) is int:\n",
    "      # Bias ou entrada\n",
    "      self.w = None\n",
    "      self.g = self.x\n",
    "    elif type(self.x) is list:\n",
    "      # Normal\n",
    "      self.w = w if type(w) is np.ndarray else np.random.random(len(self.x))\n",
    "      self.u = self.x @ self.w\n",
    "      self.g = self.function(self.u)\n",
    "    else:\n",
    "      # Não-inicializado\n",
    "      self.w = w if w is None or type(w) is np.ndarray else np.random.random(w)\n",
    "      self.g = None\n",
    "      \n",
    "  def update(self, new_x):\n",
    "      self.x = new_x\n",
    "      if not self.is_bias():\n",
    "        self.u = self.x @ self.w\n",
    "        self.g = self.function(self.u)\n",
    "      else:\n",
    "        self.g = self.x\n",
    "  \n",
    "  is_bias = lambda self: True if self.w is None else False\n",
    "  \n",
    "  __repr__ = lambda self: '{} @ {} -> {}'.format(self.x, self.w, self.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     1,
     6,
     16,
     24,
     46,
     52,
     78,
     87
    ]
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "  def __init__(self, topology):\n",
    "    self.topology = topology\n",
    "    \n",
    "    self.init_neurons()   \n",
    "    \n",
    "  def init_neurons(self):\n",
    "    # Camada de entrada\n",
    "    self.layers = [[Neuron() for i in range(self.topology[0])]]\n",
    "    self.layers[0] += [Neuron(1)] # Bias \n",
    "    \n",
    "    # Camadas ocultas e de saída\n",
    "    for i in range(1, len(self.topology)):\n",
    "      self.layers += [[Neuron(w=len(self.layers[i - 1])) for j in range(self.topology[i])]]\n",
    "      if i != len(self.topology) - 1: self.layers[i] += [Neuron(1)] # Bias\n",
    "\n",
    "  def update_neurons(self): \n",
    "    # Camada de entrada\n",
    "    [self.layers[0][i].update(self.inputs[i]) for i in range(len(self.inputs))]\n",
    "    \n",
    "    # Camadas ocultas e de saída\n",
    "    for i in range(1, len(self.layers)):\n",
    "      [n.update([e.g for e in self.layers[i - 1]]) for n in self.layers[i] if not n.is_bias()]\n",
    "        \n",
    "  def update_weights(self):\n",
    "    # Camada de saída\n",
    "    for i in range(len(self.layers[-1])):\n",
    "      # Derivada parcial\n",
    "      neuron = self.layers[-1][i]\n",
    "      neuron.pd = - (self.desired[i] - neuron.g) * neuron.g * (1 - neuron.g)\n",
    "      # Pesos\n",
    "      for j in range(len(neuron.w)):\n",
    "        neuron.w[j] -= self.learning_rate * neuron.pd * self.layers[-2][j].g\n",
    "          \n",
    "    # Camadas ocultas\n",
    "    for i in range(len(self.layers) - 2, 0, -1):\n",
    "      for j in range(len(self.layers[i]) - 1):\n",
    "        # Derivada parcial\n",
    "        neuron = self.layers[i][j]\n",
    "#         print(neuron)\n",
    "        descendents = sum([n.pd * n.w[j] for n in self.layers[i + 1] if not n.is_bias()])\n",
    "        neuron.pd = descendents * neuron.g * (1 - neuron.g)\n",
    "        # Pesos\n",
    "        for k in range(len(neuron.w)):\n",
    "          neuron.w[k] -= self.learning_rate * neuron.pd * neuron.x[k]\n",
    "  \n",
    "  def update_errors(self):\n",
    "    out_layer = self.layers[-1]\n",
    "    out_length = len(out_layer)\n",
    "    self.errors = [(out_layer[i].g - self.desired[i]) ** 2 for i in range(out_length)]\n",
    "    self.total_error = sum(self.errors) / 2\n",
    "    \n",
    "  def train(self, test_data, learning_rate=.1, precision=10**-6):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.precision = precision\n",
    "    self.epochs = 0\n",
    "    current_mse = 0\n",
    "    last_mse = 0\n",
    "    \n",
    "    while abs(current_mse - last_mse) > self.precision or self.epochs == 0:\n",
    "      last_mse = current_mse\n",
    "      \n",
    "      errors_sum = 0\n",
    "      for index, sample in test_data.iterrows():\n",
    "        self.inputs = sample[:self.topology[0]].tolist()\n",
    "        self.desired = sample[self.topology[0]:].tolist()\n",
    "        self.update_neurons()\n",
    "\n",
    "        self.update_errors()\n",
    "        errors_sum += self.total_error\n",
    "\n",
    "        self.update_weights()\n",
    "\n",
    "      self.update_neurons()\n",
    "      self.epochs += 1\n",
    "      \n",
    "      current_mse = errors_sum / test_data.shape[0]\n",
    "        \n",
    "  def test_individual(self, sample):\n",
    "    layers = cp.deepcopy(self.layers)\n",
    "    \n",
    "    [layers[0][i].update(sample[i]) for i in range(len(sample))]\n",
    "    for i in range(1, len(layers)):\n",
    "      [n.update([e.g for e in layers[i - 1]]) for n in layers[i] if not n.is_bias()]\n",
    "      \n",
    "    return [n.g for n in layers[-1]]\n",
    "  \n",
    "  def __repr__(self):\n",
    "    result = 'Topologia: {}\\t'.format(self.topology)\n",
    "    result += 'Épocas: {}\\n\\n'.format(self.epochs)\n",
    "    result += 'PESOS\\n'\n",
    "    for i in range(1, len(self.layers)):\n",
    "      result += 'Camada {}\\n'.format(i)\n",
    "      for j in range(len(self.layers[i])):\n",
    "        neuron = self.layers[i][j]\n",
    "        if not neuron.is_bias():\n",
    "          result += 'Neurônio {:2d}: {}\\n'.format(j, neuron.w)\n",
    "      result += '\\n'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/ressonancia.csv')\n",
    "df = df.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topologia: [3, 2, 1]\tÉpocas: 244\n",
       "\n",
       "PESOS\n",
       "Camada 1\n",
       "Neurônio  0: [0.84458428 0.32885161 0.62661012 0.27175785]\n",
       "Neurônio  1: [0.13855793 0.55085711 0.39489494 0.37044522]\n",
       "\n",
       "Camada 2\n",
       "Neurônio  0: [0.57306673 0.06936451 0.55377107]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aan = MLP([3, 2, 1])\n",
    "aan.train(df)\n",
    "aan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5399474860150307], 0.5625)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 199\n",
    "aan.test_individual(df.values[sample][:-1]), df.values[sample][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
