{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Alterar neurômios para iniciarem sem entrada e com seus pesos baseados em topology\n",
    "# TODO: Função update - alterar o valor dos x e passar adiante (u e g)\n",
    "class Neuron:\n",
    "  def __init__(self, x=None, w=[], function=sigmoid):\n",
    "    # function - Função de ativação\n",
    "    # x - Entrada\n",
    "    # w - Peso\n",
    "    # u - Saída do corpo\n",
    "    # g - Saída da função de ativação\n",
    "    # pd - Derivada parcial\n",
    "    \n",
    "    self.function = function\n",
    "    self.x = x\n",
    "    self.pd = None\n",
    "    \n",
    "    if self.is_bias():\n",
    "      self.w = w\n",
    "      self.u = None\n",
    "      self.g = x\n",
    "    else:\n",
    "      self.w = np.random.random(len(self.x)) if w == [] else w\n",
    "      self.u = self.x @ self.w\n",
    "      self.g = self.function(self.u)\n",
    "      \n",
    "  def update(self, new_x):\n",
    "    if not self.is_bias():\n",
    "      self.x = new_x\n",
    "      self.u = self.x @ self.w\n",
    "      self.g = self.function(self.u)\n",
    "  \n",
    "  is_bias = lambda self: True if type(self.x) is not list else False\n",
    "  \n",
    "  __repr__ = lambda self: '{} @ {} ({}) -> {}'.format(self.x, self.w, self.pd, self.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "  def __init__(self, topology):\n",
    "    self.inputs = inputs\n",
    "    self.desired = desired\n",
    "    self.topology = topology\n",
    "    self.precision = precision\n",
    "    self.learning_rate = learning_rate\n",
    "    self.errors = [0] * self.topology[-1]\n",
    "    self.total_error = 0\n",
    "    \n",
    "#     self.init_neurons()\n",
    "    self.inputs = [.05, .1]\n",
    "    self.desired = [.01, .99]\n",
    "    self.learning_rate = 0.5\n",
    "    self.layers = [[Neuron(.05), Neuron(.1), Neuron(1)]]\n",
    "    self.layers += [[Neuron([e.g for e in self.layers[0]], np.array([.15, .2, .35])), \n",
    "                     Neuron([e.g for e in self.layers[0]], np.array([.25, .3, .35])), \n",
    "                     Neuron(1)]]\n",
    "    self.layers += [[Neuron([e.g for e in self.layers[1]], np.array([.4, .45, .6])), \n",
    "                     Neuron([e.g for e in self.layers[1]], np.array([.5, .55, .6]))]]\n",
    "    \n",
    "    \n",
    "  def init_neurons(self):\n",
    "    # Camada de entrada\n",
    "    self.layers = [[Neuron(self.inputs[i]) for i in range(self.topology[0])]]\n",
    "    self.layers[0] += [Neuron(1)] # Bias \n",
    "    \n",
    "    # Camadas ocultas\n",
    "    for i in range(1, len(self.topology)):\n",
    "      self.layers += [[Neuron([e.g for e in self.layers[i - 1]]) for j in range(self.topology[i])]]\n",
    "      if i != len(self.topology) - 1: self.layers[i] += [Neuron(1)] # Bias\n",
    "\n",
    "  def update_neurons(self):\n",
    "    for i in range(1, len(self.layers)):\n",
    "      [n.update([e.g for e in self.layers[i - 1]]) for n in self.layers[i]]\n",
    "        \n",
    "  def update_weights(self):\n",
    "    # Camada de saída\n",
    "    for i in range(len(self.layers[-1])):\n",
    "      # Derivada parcial\n",
    "      neuron = self.layers[-1][i]\n",
    "      neuron.pd = - (self.desired[i] - neuron.g) * neuron.g * (1 - neuron.g)\n",
    "      # Pesos\n",
    "      for j in range(len(neuron.w)):\n",
    "        neuron.w[j] -= self.learning_rate * neuron.pd * self.layers[-2][j].g\n",
    "          \n",
    "    # Camadas ocultas\n",
    "    for i in range(len(self.layers) - 2, 0, -1):\n",
    "      for j in range(len(self.layers[i])):\n",
    "        # Derivada parcial\n",
    "        neuron = self.layers[i][j]\n",
    "        descendents = sum([n.pd * n.w[j] for n in self.layers[i + 1] if not n.is_bias()])\n",
    "        neuron.pd = descendents * neuron.g * (1 - neuron.g)\n",
    "        # Pesos\n",
    "        for k in range(len(neuron.w)):\n",
    "          neuron.w[k] -= self.learning_rate * neuron.pd * neuron.x[k]\n",
    "  \n",
    "  def update_errors(self):\n",
    "    out_layer = self.layers[-1]\n",
    "    out_length = len(out_layer)\n",
    "    \n",
    "    self.errors = [(out_layer[i].g - self.desired[i]) ** 2 for i in range(out_length)]\n",
    "    self.total_error = sum(self.errors) / 2\n",
    "    \n",
    "  def train(self):\n",
    "  \n",
    "  def __repr__(self):\n",
    "    result = 'Entradas: {}\\nSaída desejada: {}\\nErro total: {}\\n\\n'.format(self.inputs, self.desired, self.total_error)\n",
    "    result += 'Camada 0 - Entrada\\n{}\\n\\n'.format(self.layers[0])\n",
    "    for i in range(1, len(self.layers) - 1): result += 'Camada {} - Escondida \\n{}\\n\\n'.format(i, self.layers[i])\n",
    "    result += 'Camada {} - Saída\\n{}\\n\\n'.format(len(self.layers) - 1, self.layers[-1])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/impsid/.anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Entradas: [0.05, 0.1]\n",
       "Saída desejada: [0.01, 0.99]\n",
       "Erro total: 2.4381048904383838e-06\n",
       "\n",
       "Camada 0 - Entrada\n",
       "[0.05 @ [] (None) -> 0.05, 0.1 @ [] (None) -> 0.1, 1 @ [] (None) -> 1]\n",
       "\n",
       "Camada 1 - Escondida \n",
       "[[0.05, 0.1, 1] @ [0.18291248 0.26582495 1.0082495 ] (-1.0213877377663664e-05) -> 0.7396167616057072, [0.05, 0.1, 1] @ [0.28218874 0.36437748 0.99377485] (-1.0221184044840948e-05) -> 0.7396830843499616, 1 @ [] (-0.0) -> 1]\n",
       "\n",
       "Camada 2 - Saída\n",
       "[[0.7396167616057072, 0.7396830843499616, 1] @ [-1.45152738 -1.40484546 -2.33377952] (1.8137503158944566e-05) -> 0.01158382711768914, [0.7396167616057072, 0.7396830843499616, 1] @ [1.52214253 1.57305739 2.16111789] (-1.7546845346810148e-05) -> 0.9884617683899352]\n"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP([1, 0],[1],[2, 3, 1], 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
